{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amiyaguchi/wikipedia-retention\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.snap_import_user_projection import UnimodalUserProjection\n",
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "input_path = \"data/processed/enwiki-meta-compact\"\n",
    "model = UnimodalUserProjection(spark).extract(input_path).transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53595946"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.table(\"bipartite\").cache()\n",
    "spark.table(\"bipartite\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "|user_id|role_id|\n",
      "+-------+-------+\n",
      "|  44750|      1|\n",
      "|2118749|      1|\n",
      "|  84417|      1|\n",
      "| 921428|      1|\n",
      "| 282514|      1|\n",
      "+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "role_df = spark.read.csv(\n",
    "    \"data/processed/rolx-roles\",\n",
    "    schema=\"user_id INT, role_id INT\",\n",
    "    sep='\\t',\n",
    "    comment='-', \n",
    "    ignoreLeadingWhiteSpace=True\n",
    ")\n",
    "role_df.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "admin_df = spark.read.csv(\n",
    "    \"data/processed/admin_mapping.csv\",\n",
    "    schema=\"user_id INT, username STRING\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|user_id|role_id|is_admin|\n",
      "+-------+-------+--------+\n",
      "|  44750|      1|       0|\n",
      "|2118749|      1|       0|\n",
      "|  84417|      1|       0|\n",
      "| 921428|      1|       0|\n",
      "| 282514|      1|       0|\n",
      "+-------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "role_admin = (\n",
    "    role_df.join(admin_df, on=\"user_id\", how='left')\n",
    "    .selectExpr(\n",
    "        \"user_id\", \n",
    "        \"role_id\", \n",
    "        \"cast(username is not null as int) as is_admin\"\n",
    "    )\n",
    ")\n",
    "\n",
    "role_admin.show(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(role_id=0),\n",
       " Row(role_id=1),\n",
       " Row(role_id=2),\n",
       " Row(role_id=3),\n",
       " Row(role_id=4)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(role_admin.select(\"role_id\").distinct().collect())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+\n",
      "|role_id|n_users|n_admins|\n",
      "+-------+-------+--------+\n",
      "|      1|  57823|     712|\n",
      "|     15|  55728|       2|\n",
      "|     21|  51549|       0|\n",
      "|     14|  51364|       2|\n",
      "|      6|  49790|       3|\n",
      "|     24|  47307|       0|\n",
      "|     26|  44357|       6|\n",
      "|      3|  40123|       0|\n",
      "|     23|  39089|       0|\n",
      "|      0|  37421|       2|\n",
      "|     18|  35279|       1|\n",
      "|      9|  33855|       0|\n",
      "|     10|  32043|       1|\n",
      "|     20|  31615|       2|\n",
      "|     29|  29690|       4|\n",
      "|     25|  28259|       0|\n",
      "|     17|  27643|       4|\n",
      "|     27|  26358|       3|\n",
      "|     19|  23922|       0|\n",
      "|      7|  23751|       0|\n",
      "+-------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(\n",
    "    role_admin\n",
    "    .groupBy(\"role_id\")\n",
    "    .agg(\n",
    "        F.expr(\"count(distinct user_id) as n_users\"),\n",
    "        F.expr(\"sum(is_admin) as n_admins\")\n",
    "    )\n",
    "    .orderBy(F.desc(\"n_users\"))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+---+---+---+---+---+---+\n",
      "|article_id| edit_date| -1|  0|  1| 14| 18| 26|  x|\n",
      "+----------+----------+---+---+---+---+---+---+---+\n",
      "|     32208|2002-12-14|  0|  0|  1|  0|  0|  0| 58|\n",
      "|    235429|2004-09-10|  0|  0|  1|  0|  0|  0| 58|\n",
      "|     63681|2002-01-20|  0|  0|  0|  1|  0|  0| 58|\n",
      "|   1943938|2007-02-27|  0|  0|  1|  0|  0|  0| 58|\n",
      "|     53348|2004-06-08|  0|  0|  1|  0|  0|  0| 58|\n",
      "|  11133659|2007-12-08|  0|  0|  1|  0|  0|  0| 58|\n",
      "|     34648|2003-05-17|  0|  0|  1|  0|  0|  0| 58|\n",
      "|   1073920|2006-09-10|  0|  0|  1|  0|  0|  0| 58|\n",
      "|  14610731|2003-05-29|  0|  0|  1|  0|  0|  0| 58|\n",
      "|   4535938|2006-05-15|  0|  0|  1|  0|  0|  0| 58|\n",
      "|    618672|2005-09-16|  0|  0|  1|  0|  0|  0| 58|\n",
      "|    260914|2003-10-10|  0|  0|  1|  0|  0|  0| 58|\n",
      "|    593926|2005-09-19|  0|  0|  1|  0|  0|  0| 58|\n",
      "|     43507|2003-08-29|  0|  0|  1|  0|  0|  0| 58|\n",
      "|    347833|2004-07-04|  0|  0|  1|  0|  0|  0| 58|\n",
      "|     58893|2003-03-29|  0|  0|  1|  0|  0|  0| 58|\n",
      "|    842430|2006-08-25|  0|  0|  1|  0|  0|  0| 58|\n",
      "|     44510|2007-04-25|  0|  0|  1|  0|  0|  0| 58|\n",
      "|     53460|2002-05-25|  0|  0|  1|  0|  0|  0| 58|\n",
      "|    348226|2004-09-04|  0|  0|  1|  0|  0|  0| 58|\n",
      "+----------+----------+---+---+---+---+---+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# article_roles = (\n",
    "#     spark.table(\"bipartite\").limit(1000)\n",
    "#     .join(role_admin, on=\"user_id\", how=\"left\")\n",
    "#     .na.fill({\"role_id\": -1, \"is_admin\": 0})\n",
    "#     # count roles per block\n",
    "#     .groupby(\"article_id\", \"edit_date\")\n",
    "#     .pivot(\"role_id\")\n",
    "#     .agg(F.expr(\"count(distinct user_id) as n_users\"))\n",
    "#     .fillna(0)\n",
    "# )\n",
    "\n",
    "\n",
    "article_roles = (\n",
    "    spark.table(\"bipartite\").limit(1000)\n",
    "    .join(role_admin, on=\"user_id\", how=\"left\")\n",
    "    .na.fill({\"role_id\": -1, \"is_admin\": 0})\n",
    "    # count roles per block\n",
    "    .groupby(\"article_id\", \"edit_date\", \"role_id\")\n",
    "    .agg(F.expr(\"count(distinct user_id) as n_users\"))\n",
    ")\n",
    "\n",
    "article_total = (\n",
    "    spark.table(\"bipartite\")\n",
    "    .groupby(\"article_id\", \"edit_date\")\n",
    "    .agg(F.expr(\"count(distinct user_id) as total_users\"))\n",
    ")\n",
    "\n",
    "normalized_article_roles = (\n",
    "    article_roles\n",
    "    .join(article_total, on=[\"article_id\", \"edit_date\"])\n",
    "    .withColumn(\"n_users\", F.expr(\"n_users/total_users\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------------+\n",
      "|min(role_id)|max(role_id)|\n",
      "+------------+------------+\n",
      "|           0|          30|\n",
      "+------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "role_df.selectExpr(\"min(role_id)\", \"max(role_id)\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "bipartite = (\n",
    "    spark.table(\"bipartite\")\n",
    "    .join(role_admin, on=\"user_id\", how=\"left\")\n",
    "    .na.fill({\"role_id\": -1, \"is_admin\": 0})\n",
    ")\n",
    "\n",
    "article_roles = (\n",
    "    bipartite\n",
    "    .groupBy(\"article_id\", \"edit_date\", \"role_id\")\n",
    "    .agg(F.expr(\"count(user_id) as n_users\"))\n",
    ")\n",
    "\n",
    "\n",
    "def seq_func(acc, data):\n",
    "    acc[data[0]] += data[1]\n",
    "    return acc\n",
    "\n",
    "def comb_func(v1, v2): \n",
    "    return v1 + v2\n",
    "\n",
    "n_roles = 31  # max+1 of the dataframe role_id\n",
    "article_role_vec = (\n",
    "    article_roles\n",
    "    .rdd\n",
    "    .map(lambda r: ((r.article_id, r.edit_date), (r.role_id, r.n_users)))\n",
    "    .aggregateByKey(\n",
    "        np.zeros(n_roles),\n",
    "        seq_func,\n",
    "        comb_func\n",
    "    )\n",
    ")\n",
    "\n",
    "# this is ugly, use a pandas df instead\n",
    "features = (\n",
    "    bipartite\n",
    "    .select(\"user_id\", \"article_id\", \"edit_date\")\n",
    "    .rdd\n",
    "    .map(lambda r: ((r.article_id, r.edit_date), r.user_id))\n",
    "    .join(article_role_vec)\n",
    "    .map(lambda r: (r[1][0], r[1][1]))\n",
    "    .map(lambda r: (r[0], (r[1]/np.sum(r[1]), 1)))\n",
    "    .reduceByKey(lambda v1, v2: (v1[0] + v2[0], v1[1] + v2[1]))\n",
    "    .map(lambda r: (r[0], *(r[1][0]/r[1][1]).tolist()))\n",
    ").toDF()\n",
    "\n",
    "features.repartition(4).write.parquet(\"data/processed/avg_role_features\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
