{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/amiyaguchi/wikipedia-retention\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37304.0</td>\n",
       "      <td>10209240.0</td>\n",
       "      <td>15737186.0</td>\n",
       "      <td>36118260.0</td>\n",
       "      <td>968.214111</td>\n",
       "      <td>7.117394e+09</td>\n",
       "      <td>1.907944e+05</td>\n",
       "      <td>1.142605e+11</td>\n",
       "      <td>3062955.0</td>\n",
       "      <td>3443599.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.047179e+09</td>\n",
       "      <td>1216278.250</td>\n",
       "      <td>2.122445e+10</td>\n",
       "      <td>6621282.0</td>\n",
       "      <td>9047967.0</td>\n",
       "      <td>1223658.500</td>\n",
       "      <td>2.100211e+10</td>\n",
       "      <td>6632294.5</td>\n",
       "      <td>1221359.750</td>\n",
       "      <td>6624842.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3546.0</td>\n",
       "      <td>720717.0</td>\n",
       "      <td>10319353.0</td>\n",
       "      <td>11757241.0</td>\n",
       "      <td>3315.634766</td>\n",
       "      <td>2.740751e+09</td>\n",
       "      <td>7.729135e+05</td>\n",
       "      <td>2.185514e+10</td>\n",
       "      <td>6163323.0</td>\n",
       "      <td>7705844.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2.029646e+09</td>\n",
       "      <td>1223429.500</td>\n",
       "      <td>2.112501e+10</td>\n",
       "      <td>6613167.0</td>\n",
       "      <td>9054072.0</td>\n",
       "      <td>1224354.250</td>\n",
       "      <td>2.107670e+10</td>\n",
       "      <td>6618573.5</td>\n",
       "      <td>1223415.875</td>\n",
       "      <td>6619284.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2315.0</td>\n",
       "      <td>553232.0</td>\n",
       "      <td>8424956.0</td>\n",
       "      <td>9529105.0</td>\n",
       "      <td>4116.244141</td>\n",
       "      <td>2.464032e+09</td>\n",
       "      <td>1.064377e+06</td>\n",
       "      <td>1.700661e+10</td>\n",
       "      <td>7346266.0</td>\n",
       "      <td>9470891.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.045110e+09</td>\n",
       "      <td>1217417.750</td>\n",
       "      <td>2.100859e+10</td>\n",
       "      <td>6648297.0</td>\n",
       "      <td>9077289.0</td>\n",
       "      <td>1219390.375</td>\n",
       "      <td>2.104158e+10</td>\n",
       "      <td>6638263.0</td>\n",
       "      <td>1220817.750</td>\n",
       "      <td>6632523.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>95.0</td>\n",
       "      <td>1712.0</td>\n",
       "      <td>1006831.0</td>\n",
       "      <td>1010160.0</td>\n",
       "      <td>10633.262695</td>\n",
       "      <td>2.003104e+08</td>\n",
       "      <td>2.108530e+06</td>\n",
       "      <td>8.012986e+08</td>\n",
       "      <td>8434722.0</td>\n",
       "      <td>12641187.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.039572e+09</td>\n",
       "      <td>1220639.500</td>\n",
       "      <td>2.094408e+10</td>\n",
       "      <td>6651448.0</td>\n",
       "      <td>9086844.0</td>\n",
       "      <td>1218765.000</td>\n",
       "      <td>2.108085e+10</td>\n",
       "      <td>6635371.0</td>\n",
       "      <td>1221411.000</td>\n",
       "      <td>6632723.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>451.0</td>\n",
       "      <td>26471.0</td>\n",
       "      <td>2999391.0</td>\n",
       "      <td>3051882.0</td>\n",
       "      <td>6766.922363</td>\n",
       "      <td>6.881007e+08</td>\n",
       "      <td>1.525722e+06</td>\n",
       "      <td>3.480699e+09</td>\n",
       "      <td>7717736.0</td>\n",
       "      <td>10762418.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.037694e+09</td>\n",
       "      <td>1220722.375</td>\n",
       "      <td>2.099337e+10</td>\n",
       "      <td>6641782.5</td>\n",
       "      <td>9077333.0</td>\n",
       "      <td>1220178.750</td>\n",
       "      <td>2.107218e+10</td>\n",
       "      <td>6631758.0</td>\n",
       "      <td>1221793.750</td>\n",
       "      <td>6629538.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0           1           2           3             4             5   \\\n",
       "0  37304.0  10209240.0  15737186.0  36118260.0    968.214111  7.117394e+09   \n",
       "1   3546.0    720717.0  10319353.0  11757241.0   3315.634766  2.740751e+09   \n",
       "2   2315.0    553232.0   8424956.0   9529105.0   4116.244141  2.464032e+09   \n",
       "3     95.0      1712.0   1006831.0   1010160.0  10633.262695  2.003104e+08   \n",
       "4    451.0     26471.0   2999391.0   3051882.0   6766.922363  6.881007e+08   \n",
       "\n",
       "             6             7          8           9     ...                52  \\\n",
       "0  1.907944e+05  1.142605e+11  3062955.0   3443599.0    ...      2.047179e+09   \n",
       "1  7.729135e+05  2.185514e+10  6163323.0   7705844.5    ...      2.029646e+09   \n",
       "2  1.064377e+06  1.700661e+10  7346266.0   9470891.0    ...      2.045110e+09   \n",
       "3  2.108530e+06  8.012986e+08  8434722.0  12641187.0    ...      2.039572e+09   \n",
       "4  1.525722e+06  3.480699e+09  7717736.0  10762418.0    ...      2.037694e+09   \n",
       "\n",
       "            53            54         55         56           57            58  \\\n",
       "0  1216278.250  2.122445e+10  6621282.0  9047967.0  1223658.500  2.100211e+10   \n",
       "1  1223429.500  2.112501e+10  6613167.0  9054072.0  1224354.250  2.107670e+10   \n",
       "2  1217417.750  2.100859e+10  6648297.0  9077289.0  1219390.375  2.104158e+10   \n",
       "3  1220639.500  2.094408e+10  6651448.0  9086844.0  1218765.000  2.108085e+10   \n",
       "4  1220722.375  2.099337e+10  6641782.5  9077333.0  1220178.750  2.107218e+10   \n",
       "\n",
       "          59           60         61  \n",
       "0  6632294.5  1221359.750  6624842.5  \n",
       "1  6618573.5  1223415.875  6619284.0  \n",
       "2  6638263.0  1220817.750  6632523.0  \n",
       "3  6635371.0  1221411.000  6632723.5  \n",
       "4  6631758.0  1221793.750  6629538.0  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "rolx_vec = pd.read_csv(\n",
    "    \"data/processed/user-network-v3-v\", \n",
    "    header=None,\n",
    "    sep=' '\n",
    ")\n",
    "rolx_vec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2164770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>32875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>261299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>94306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0        1\n",
       "0  0     7580\n",
       "1  1  2164770\n",
       "2  2    32875\n",
       "3  3   261299\n",
       "4  4    94306"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rolx_mapping = pd.read_csv(\n",
    "    \"data/processed/user-network-v3-mappings\",\n",
    "    header=None,\n",
    "    skiprows=1,\n",
    "    sep=' '\n",
    ")\n",
    "\n",
    "rolx_mapping.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([rolx_mapping, rolx_vec], axis=1).iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure to join with the mapping file afterwards\n",
    "from sklearn.decomposition import NMF\n",
    "import numpy as np\n",
    "\n",
    "nmf = NMF(\n",
    "    n_components=16, \n",
    "    solver='mu', \n",
    "    beta_loss='kullback-leibler', \n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "X = df.values[:, 1:]\n",
    "W = nmf.fit_transform(X)\n",
    "H = nmf.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "art.txt       auth.txt      ecc_clust.txt hub.txt       pr.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls data/interim/rolesense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([df.iloc[:, 0], pd.DataFrame(W)]).to_csv(\"data/processed/rolx-nmf-G.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "enwiki = spark.read.parquet(\"data/processed/enwiki-meta-compact\")\n",
    "enwiki.createOrReplaceTempView(\"enwiki\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "    cast(user_id as int) as user_id,\n",
    "    count(distinct article_id) as n_articles,\n",
    "    count(*) as n_edits,\n",
    "    log(sum(log(textdata))) as edit_count\n",
    "FROM enwiki\n",
    "WHERE cast(user_id as int) is not null\n",
    "GROUP BY 1\n",
    "\"\"\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr = pd.read_csv(\n",
    "    \"data/interim/rolesense/pr.txt\", \n",
    "    header=None, \n",
    "    names=[\"user_id\", \"pagerank\"]\n",
    ")\n",
    "hub = pd.read_csv(\n",
    "    \"data/interim/rolesense/hub.txt\", \n",
    "    header=None,\n",
    "    names=[\"user_id\", \"hub\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_stats = (\n",
    "    user_df\n",
    "    .merge(pr, on=\"user_id\")\n",
    "    .merge(hub, on=\"user_id\")\n",
    "    .fillna(0)\n",
    ")\n",
    "\n",
    "user_stats.to_csv(\"data/processed/nodesense-v1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = user_stats[user_stats.edit_count > 0].iloc[:10000, 1:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5) (10000, 16) (16, 62)\n"
     ]
    }
   ],
   "source": [
    "print(M.shape, W.shape, H.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class NMF in module sklearn.decomposition.nmf:\n",
      "\n",
      "class NMF(sklearn.base.BaseEstimator, sklearn.base.TransformerMixin)\n",
      " |  NMF(n_components=None, init=None, solver='cd', beta_loss='frobenius', tol=0.0001, max_iter=200, random_state=None, alpha=0.0, l1_ratio=0.0, verbose=0, shuffle=False)\n",
      " |  \n",
      " |  Non-Negative Matrix Factorization (NMF)\n",
      " |  \n",
      " |  Find two non-negative matrices (W, H) whose product approximates the non-\n",
      " |  negative matrix X. This factorization can be used for example for\n",
      " |  dimensionality reduction, source separation or topic extraction.\n",
      " |  \n",
      " |  The objective function is::\n",
      " |  \n",
      " |      0.5 * ||X - WH||_Fro^2\n",
      " |      + alpha * l1_ratio * ||vec(W)||_1\n",
      " |      + alpha * l1_ratio * ||vec(H)||_1\n",
      " |      + 0.5 * alpha * (1 - l1_ratio) * ||W||_Fro^2\n",
      " |      + 0.5 * alpha * (1 - l1_ratio) * ||H||_Fro^2\n",
      " |  \n",
      " |  Where::\n",
      " |  \n",
      " |      ||A||_Fro^2 = \\sum_{i,j} A_{ij}^2 (Frobenius norm)\n",
      " |      ||vec(A)||_1 = \\sum_{i,j} abs(A_{ij}) (Elementwise L1 norm)\n",
      " |  \n",
      " |  For multiplicative-update ('mu') solver, the Frobenius norm\n",
      " |  (0.5 * ||X - WH||_Fro^2) can be changed into another beta-divergence loss,\n",
      " |  by changing the beta_loss parameter.\n",
      " |  \n",
      " |  The objective function is minimized with an alternating minimization of W\n",
      " |  and H.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <NMF>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_components : int or None\n",
      " |      Number of components, if n_components is not set all features\n",
      " |      are kept.\n",
      " |  \n",
      " |  init :  'random' | 'nndsvd' |  'nndsvda' | 'nndsvdar' | 'custom'\n",
      " |      Method used to initialize the procedure.\n",
      " |      Default: 'nndsvd' if n_components < n_features, otherwise random.\n",
      " |      Valid options:\n",
      " |  \n",
      " |      - 'random': non-negative random matrices, scaled with:\n",
      " |          sqrt(X.mean() / n_components)\n",
      " |  \n",
      " |      - 'nndsvd': Nonnegative Double Singular Value Decomposition (NNDSVD)\n",
      " |          initialization (better for sparseness)\n",
      " |  \n",
      " |      - 'nndsvda': NNDSVD with zeros filled with the average of X\n",
      " |          (better when sparsity is not desired)\n",
      " |  \n",
      " |      - 'nndsvdar': NNDSVD with zeros filled with small random values\n",
      " |          (generally faster, less accurate alternative to NNDSVDa\n",
      " |          for when sparsity is not desired)\n",
      " |  \n",
      " |      - 'custom': use custom matrices W and H\n",
      " |  \n",
      " |  solver : 'cd' | 'mu'\n",
      " |      Numerical solver to use:\n",
      " |      'cd' is a Coordinate Descent solver.\n",
      " |      'mu' is a Multiplicative Update solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Coordinate Descent solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |         Multiplicative Update solver.\n",
      " |  \n",
      " |  beta_loss : float or string, default 'frobenius'\n",
      " |      String must be in {'frobenius', 'kullback-leibler', 'itakura-saito'}.\n",
      " |      Beta divergence to be minimized, measuring the distance between X\n",
      " |      and the dot product WH. Note that values different from 'frobenius'\n",
      " |      (or 2) and 'kullback-leibler' (or 1) lead to significantly slower\n",
      " |      fits. Note that for beta_loss <= 0 (or 'itakura-saito'), the input\n",
      " |      matrix X cannot contain zeros. Used only in 'mu' solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  tol : float, default: 1e-4\n",
      " |      Tolerance of the stopping condition.\n",
      " |  \n",
      " |  max_iter : integer, default: 200\n",
      " |      Maximum number of iterations before timing out.\n",
      " |  \n",
      " |  random_state : int, RandomState instance or None, optional, default: None\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  alpha : double, default: 0.\n",
      " |      Constant that multiplies the regularization terms. Set it to zero to\n",
      " |      have no regularization.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *alpha* used in the Coordinate Descent solver.\n",
      " |  \n",
      " |  l1_ratio : double, default: 0.\n",
      " |      The regularization mixing parameter, with 0 <= l1_ratio <= 1.\n",
      " |      For l1_ratio = 0 the penalty is an elementwise L2 penalty\n",
      " |      (aka Frobenius Norm).\n",
      " |      For l1_ratio = 1 it is an elementwise L1 penalty.\n",
      " |      For 0 < l1_ratio < 1, the penalty is a combination of L1 and L2.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         Regularization parameter *l1_ratio* used in the Coordinate Descent\n",
      " |         solver.\n",
      " |  \n",
      " |  verbose : bool, default=False\n",
      " |      Whether to be verbose.\n",
      " |  \n",
      " |  shuffle : boolean, default: False\n",
      " |      If true, randomize the order of coordinates in the CD solver.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *shuffle* parameter used in the Coordinate Descent solver.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  components_ : array, [n_components, n_features]\n",
      " |      Factorization matrix, sometimes called 'dictionary'.\n",
      " |  \n",
      " |  reconstruction_err_ : number\n",
      " |      Frobenius norm of the matrix difference, or beta-divergence, between\n",
      " |      the training data ``X`` and the reconstructed data ``WH`` from\n",
      " |      the fitted model.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      Actual number of iterations.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> import numpy as np\n",
      " |  >>> X = np.array([[1, 1], [2, 1], [3, 1.2], [4, 1], [5, 0.8], [6, 1]])\n",
      " |  >>> from sklearn.decomposition import NMF\n",
      " |  >>> model = NMF(n_components=2, init='random', random_state=0)\n",
      " |  >>> W = model.fit_transform(X)\n",
      " |  >>> H = model.components_\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  Cichocki, Andrzej, and P. H. A. N. Anh-Huy. \"Fast local algorithms for\n",
      " |  large scale nonnegative matrix and tensor factorizations.\"\n",
      " |  IEICE transactions on fundamentals of electronics, communications and\n",
      " |  computer sciences 92.3: 708-721, 2009.\n",
      " |  \n",
      " |  Fevotte, C., & Idier, J. (2011). Algorithms for nonnegative matrix\n",
      " |  factorization with the beta-divergence. Neural Computation, 23(9).\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      NMF\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_components=None, init=None, solver='cd', beta_loss='frobenius', tol=0.0001, max_iter=200, random_state=None, alpha=0.0, l1_ratio=0.0, verbose=0, shuffle=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None, **params)\n",
      " |      Learn a NMF model for the data X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Data matrix to be decomposed\n",
      " |      \n",
      " |      y : Ignored\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, W=None, H=None)\n",
      " |      Learn a NMF model for the data X and returns the transformed data.\n",
      " |      \n",
      " |      This is more efficient than calling fit followed by transform.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Data matrix to be decomposed\n",
      " |      \n",
      " |      y : Ignored\n",
      " |      \n",
      " |      W : array-like, shape (n_samples, n_components)\n",
      " |          If init='custom', it is used as initial guess for the solution.\n",
      " |      \n",
      " |      H : array-like, shape (n_components, n_features)\n",
      " |          If init='custom', it is used as initial guess for the solution.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      W : array, shape (n_samples, n_components)\n",
      " |          Transformed data.\n",
      " |  \n",
      " |  inverse_transform(self, W)\n",
      " |      Transform data back to its original space.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      W : {array-like, sparse matrix}, shape (n_samples, n_components)\n",
      " |          Transformed data matrix\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Data matrix of original shape\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Transform the data X according to the fitted NMF model\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Data matrix to be transformed by the model\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      W : array, shape (n_samples, n_components)\n",
      " |          Transformed data\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : boolean, optional\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(NMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodesense = NMF(\n",
    "    n_components=16,\n",
    "    solver='mu', \n",
    "    beta_loss=\"kullback-leibler\", \n",
    "    init='custom', \n",
    "    max_iter=1000\n",
    ")\n",
    "\n",
    "test = np.ones((5, 16))\n",
    "E_t = nodesense.fit_transform(M.T,W=test, H=W.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5251821.950319212"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.power(M - W.dot(E_t.T), 2).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 16)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E_t.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
